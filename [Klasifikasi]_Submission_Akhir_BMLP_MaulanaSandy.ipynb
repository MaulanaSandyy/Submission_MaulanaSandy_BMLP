{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Import Library**"
      ],
      "metadata": {
        "id": "fKADPWcFKlj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
      ],
      "metadata": {
        "id": "LgA3ERnVn84N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Memuat Dataset dari Hasil Clustering**"
      ],
      "metadata": {
        "id": "f3YIEnAFKrKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
      ],
      "metadata": {
        "id": "Ey3ItwTen_7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat data hasil clustering\n",
        "dataframe = pd.read_csv('Clustered_Customers.csv')"
      ],
      "metadata": {
        "id": "GHCGNTyrM5fS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleksi hanya kolom numerik untuk analisis lebih lanjut\n",
        "numeric_columns = dataframe.select_dtypes(include=['float64', 'int64']).columns\n",
        "dataframe_numeric = dataframe[numeric_columns]\n",
        "\n",
        "# Menambahkan kembali kolom 'ClusterGroup' jika diperlukan\n",
        "if 'ClusterGroup' in dataframe.columns:\n",
        "    dataframe_numeric['ClusterGroup'] = dataframe['ClusterGroup']\n",
        "\n",
        "print(dataframe.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz-rsBGcLLPs",
        "outputId": "f183a163-8236-48c8-de39-fe53bf55e853"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   CustomerID  Gender       Age  Annual Income ($)  Spending Score (1-100)  \\\n",
            "0           1  Doctor -1.052345          -2.086675               -0.431850   \n",
            "1           2  Doctor -0.981941          -1.650205                1.069755   \n",
            "2           3  Artist -1.017143          -0.537207               -1.611684   \n",
            "3           4  Artist -0.911538          -1.126441                0.926745   \n",
            "4           5  Artist -0.629924          -1.584734               -0.396098   \n",
            "\n",
            "      Profession  Work Experience  Family Size  ClusterGroup  \n",
            "0     Healthcare                1            4             2  \n",
            "1       Engineer                3            3             2  \n",
            "2       Engineer                1            1             2  \n",
            "3         Lawyer                0            2             2  \n",
            "4  Entertainment                2            6             2  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-5bd7b4d18200>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe_numeric['ClusterGroup'] = dataframe['ClusterGroup']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Data Splitting**"
      ],
      "metadata": {
        "id": "KkPem5eWL2UP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
      ],
      "metadata": {
        "id": "YYj1rl_JNI9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pastikan 'ClusterGroup' digunakan sebagai label\n",
        "data_features = dataframe_numeric.drop(columns=['ClusterGroup'], errors='ignore')\n",
        "\n",
        "data_labels = dataframe['ClusterGroup']\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(\n",
        "    data_features, data_labels, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "OubAW-7ONKVj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Membangun Model Klasifikasi**\n"
      ],
      "metadata": {
        "id": "IVPbB03CMhTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **a. Membangun Model Klasifikasi**"
      ],
      "metadata": {
        "id": "Ned1pL9zMmBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.\n",
        "\n",
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).\n",
        "2. Latih model menggunakan data latih."
      ],
      "metadata": {
        "id": "WAWzPOE4Nkti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = {\n",
        "    \"DecisionTree\": DecisionTreeClassifier(),\n",
        "    \"RandomForest\": RandomForestClassifier(),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "}\n",
        "\n",
        "results_summary = {}"
      ],
      "metadata": {
        "id": "4JYxBe87NLDk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tulis narasi atau penjelasan algoritma yang Anda gunakan."
      ],
      "metadata": {
        "id": "seYoHNY3XU1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisis Penggunaan Algoritma:\n",
        "\n",
        "1. Decision Tree digunakan sebagai baseline karena sederhana dan mudah diinterpretasikan.\n",
        "2. Random Forest digunakan untuk meningkatkan akurasi dan mengurangi risiko overfitting dengan prinsip ensemble.\n",
        "3. KNN dipilih karena efektif untuk data sederhana, meskipun membutuhkan preprocessing tambahan seperti standarisasi fitur.\n",
        "Pemilihan algoritma ini memungkinkan perbandingan antara model berbasis pohon (Decision Tree dan Random Forest) dengan model berbasis jarak (KNN), sehingga memberikan pandangan yang lebih luas terhadap performa pada dataset."
      ],
      "metadata": {
        "id": "Mht5x88eMZzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **b. Evaluasi Model Klasifikasi**"
      ],
      "metadata": {
        "id": "ergzChZFEL-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Lakukan prediksi menggunakan data uji.\n",
        "2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).\n",
        "3. Buat confusion matrix untuk melihat detail prediksi benar dan salah."
      ],
      "metadata": {
        "id": "zOm68u-7NpLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, classifier in classifiers.items():\n",
        "    # Melatih model\n",
        "    classifier.fit(features_train, labels_train)\n",
        "    predictions = classifier.predict(features_test)\n",
        "\n",
        "    # Evaluasi model\n",
        "    accuracy = accuracy_score(labels_test, predictions)\n",
        "    precision = precision_score(labels_test, predictions, average='weighted')\n",
        "    recall = recall_score(labels_test, predictions, average='weighted')\n",
        "    f1 = f1_score(labels_test, predictions, average='weighted')\n",
        "    confusion_mat = confusion_matrix(labels_test, predictions)\n",
        "\n",
        "    results_summary[model_name] = {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-Score\": f1,\n",
        "        \"ConfusionMatrix\": confusion_mat,\n",
        "    }"
      ],
      "metadata": {
        "id": "tMq4QAssNLip"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tulis hasil evaluasi algoritma yang digunakan, jika Anda menggunakan 2 algoritma, maka bandingkan hasilnya."
      ],
      "metadata": {
        "id": "H4_9OwrsXZlz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **e. Analisis Hasil Evaluasi Model Klasifikasi**"
      ],
      "metadata": {
        "id": "ZRsOdm4uEgAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Bandingkan hasil evaluasi sebelum dan setelah tuning (jika dilakukan).\n",
        "2. Identifikasi kelemahan model, seperti:\n",
        "  - Precision atau Recall rendah untuk kelas tertentu.\n",
        "  - Apakah model mengalami overfitting atau underfitting?\n",
        "3. Berikan rekomendasi tindakan lanjutan, seperti mengumpulkan data tambahan atau mencoba algoritma lain jika hasil belum memuaskan."
      ],
      "metadata": {
        "id": "Hm3BhSi6N4_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Identifikasi Model\n",
        "**Precision, Recall, dan F1-Score:** Semua metrik menunjukkan hasil sempurna (1.0000) untuk ketiga algoritma, yang berarti tidak ada kesalahan klasifikasi pada data uji.  \n",
        "**Confusion Matrix:** Tidak ada prediksi yang keliru, dan setiap kelas teridentifikasi dengan akurat. Namun, hasil ini bisa menandakan adanya masalah potensial, seperti:\n",
        "- Dataset yang terlalu sederhana atau cluster yang sangat terpisah, sehingga model tidak diuji dalam kondisi yang lebih kompleks.\n",
        "- Kebocoran data: Jika informasi dari data uji secara tidak langsung masuk ke data latih, model dapat menunjukkan performa yang sempurna namun tidak realistis.\n",
        "\n",
        "#### Analisis Fitting\n",
        "**Overfitting:** Model menunjukkan performa sempurna pada data uji, tetapi ini bisa berarti model terlalu \"mengingat\" data daripada memahami pola yang sebenarnya. Jika dataset mengandung noise atau kurang bervariasi, risiko overfitting meningkat.  \n",
        "**Underfitting:** Tidak terdeteksi karena metrik evaluasi yang sempurna, yang menunjukkan bahwa model mampu menangkap pola dalam data dengan sangat baik (atau bahkan terlalu baik).\n",
        "\n",
        "#### Rekomendasi Tindakan Lanjutan\n",
        "1. **Validasi Model dengan Cross-Validation:** Terapkan k-fold cross-validation untuk menguji kemampuan generalisasi model pada seluruh dataset. Ini membantu memastikan bahwa performa model konsisten dan tidak hanya baik pada satu subset data.\n",
        "2. **Analisis Dataset:** Pastikan tidak ada kebocoran data, seperti fitur yang terlalu berkorelasi langsung dengan label (kolom Cluster). Periksa distribusi data untuk setiap fitur dan kelas agar dataset mencerminkan kondisi dunia nyata.\n",
        "3. **Menggunakan Dataset yang Lebih Kompleks:** Jika dataset saat ini terlalu sederhana atau tersegmentasi, pertimbangkan untuk mengumpulkan data tambahan yang lebih bervariasi dan kompleks.\n",
        "4. **Eksperimen dengan Algoritma Lain:** Cobalah algoritma lain seperti Logistic Regression, Support Vector Machines (SVM), atau Gradient Boosting (misalnya, XGBoost, LightGBM) untuk membandingkan performa.\n",
        "5. **Tuning Hyperparameter:** Lakukan pencarian hyperparameter untuk model seperti Random Forest atau KNN untuk memastikan hasil yang optimal.\n",
        "6. **Evaluasi dengan Data Baru:** Jika memungkinkan, uji model dengan dataset baru untuk menilai kemampuannya dalam menangani data yang belum pernah dilihat sebelumnya."
      ],
      "metadata": {
        "id": "woBgxkjUpTU3"
      }
    }
  ]
}